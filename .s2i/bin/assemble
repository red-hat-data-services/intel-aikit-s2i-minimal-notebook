#!/bin/bash

set -x

set -eo pipefail

source activate ${CONDA_ROOT}

# TODO: For now we don't need to run this but eventually if that's needed we need to do the follwoing:
# mkdir -p /usr/libexec/s2i
# curl https://raw.githubusercontent.com/thoth-station/s2i-thoth/master/assemble > /usr/libexec/s2i/assemble
# chmod +x /usr/libexec/s2i/assemble
# pip install thamos

# Run the original Python S2I assemble script to install packages.

# /usr/libexec/s2i/assemble

# Remove the cached package dependencies files generated from s2i assemble script.
rm -rf /tmp/Pipfile.lock
rm -rf /tmp/requirements.txt

########################################################################
# INFO: Install everything that's required for Jupyter notebooks here.
########################################################################

# Ensure we are using the latest pip and wheel packages.

# Install pipenv for jupyter-nbrequirements to use
# TODO: This should be removed once nbrequirements can use Thoth + micropipenv only
# conda install -c conda-forge pipenv>=2020.11.15

# Install mod_wsgi for use in optional webdav support.

conda install -y -c conda-forge 'mod_wsgi>=4.6.8'

# Install supervisord for managing multiple applications.

conda install -y 'supervisor>=4.1.0'

# Install base packages needed for running Jupyter Notebooks.

conda install -y --file /tmp/src/requirements.txt

npm cache clean --force

rm -rf $HOME/.cache/yarn
rm -rf $HOME/.node-gyp

# Copy into place default config files for Jupyter and Apache webdav.

mv /tmp/src/jupyter_notebook_config.py ${APP_ROOT}/etc/
mv /tmp/src/jupyter_kernel_gateway_config.py ${APP_ROOT}/etc/
mv /tmp/src/httpd-webdav.conf ${APP_ROOT}/etc/

# This S2I assemble script is only used when creating the custom image.
# For when running the image, or using it as a S2I builder, we use a second
# set of custom S2I scripts. We now need to move these into the correct
# location and have the custom image use those by dropping in an image
# metadata file which overrides the labels of the base image.

mkdir -p ${APP_ROOT}/.s2i

mv /tmp/src/builder/image_metadata.json ${APP_ROOT}/.s2i/image_metadata.json

mv /tmp/src/builder ${APP_ROOT}/builder

mv /tmp/src/supervisor ${APP_ROOT}/etc/supervisor

mv /tmp/src/gateway ${APP_ROOT}/gateway

mkdir ${APP_ROOT}/bin

mv /tmp/src/*.sh ${APP_ROOT}/bin

# Install oc command line client for OpenShift cluster.

curl -s -o ${APP_ROOT}/oc.tar.gz https://mirror.openshift.com/pub/openshift-v3/clients/3.11.374/linux/oc.tar.gz && \
    tar -C ${APP_ROOT}/bin -zxf ${APP_ROOT}/oc.tar.gz oc && \
    mv ${APP_ROOT}/bin/oc ${APP_ROOT}/bin/oc-3.11 && \
    rm ${APP_ROOT}/oc.tar.gz

curl -s -o ${APP_ROOT}/oc.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/oc/latest/linux/oc.tar.gz && \
    tar -C ${APP_ROOT}/bin -zxf ${APP_ROOT}/oc.tar.gz oc && \
    mv ${APP_ROOT}/bin/oc ${APP_ROOT}/bin/oc-4 && \
    rm ${APP_ROOT}/oc.tar.gz

ln -s ${APP_ROOT}/bin/oc-wrapper.sh ${APP_ROOT}/bin/oc

curl -Ls -o /tmp/kustomize.tar.gz https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize/v3.9.4/kustomize_v3.9.4_linux_amd64.tar.gz && \
    tar -C ${APP_ROOT}/bin -zxf /tmp/kustomize.tar.gz kustomize && \
    rm /tmp/kustomize.tar.gz

# Ensure passwd/group file intercept happens for any shell environment.

echo "source ${APP_ROOT}/etc/generate_container_user" >> ${APP_ROOT}/etc/scl_enable

# Install packages required by the proxy process.
cd ${APP_ROOT}/gateway
npm install --production

# Create additional directories.

echo " -----> Creating additional directories."

mkdir -p ${APP_ROOT}/data

# Generate default supervisord.conf file.
# ${APP_ROOT}/bin/echo_supervisord_conf | \
echo_supervisord_conf | \
    sed -e 's%^logfile=/tmp/supervisord.log%logfile=/dev/fd/1%' \
        -e 's%^logfile_maxbytes=50MB%logfile_maxbytes=0%' > \
        ${APP_ROOT}/etc/supervisord.conf

cat >> ${APP_ROOT}/etc/supervisord.conf << EOF

[include]
files = ${APP_ROOT}/etc/supervisor/*.conf
EOF

# Install and enable default nbextensions

conda install -y -c conda-forge jupyter_contrib_nbextensions

jupyter contrib nbextension install --sys-prefix

jupyter nbextension install --sys-prefix https://raw.githubusercontent.com/vpavlin/jupyter-publish-extension/master/publish.js
jupyter nbextension enable  --sys-prefix publish

# Enable the extensions configurator

conda install -y -c conda-forge jupyter_nbextensions_configurator

jupyter nbextensions_configurator enable --sys-prefix

jupyter lab build

# Apply custom notebook configuration

if [ -d "${APP_ROOT}/src/.jupyter/" ]; then
    rsync \
        --link-dest="${APP_ROOT}/src/.jupyter/" \
        --recursive \
        --verbose \
        "${APP_ROOT}/src/.jupyter/" ${APP_ROOT}/etc/jupyter
fi

# fix 'impi_rt' symlinks
if [ -d "${CONDA_ROOT}/envs/${CONDA_ENV_MODIN}/bin/libfabric" ]; then
  ln -sf ${CONDA_ROOT}/envs/${CONDA_ENV_MODIN}/bin/libfabric/fi_* ${CONDA_ROOT}/envs/${CONDA_ENV_MODIN}/bin/
elif [ -d "${CONDA_ROOT}/envs/${CONDA_ENV_PT}/bin/libfabric" ]; then
  ln -sf ${CONDA_ROOT}/envs/${CONDA_ENV_PT}/bin/libfabric/fi_* ${CONDA_ROOT}/envs/${CONDA_ENV_PT}/bin/
elif [ -d "${CONDA_ROOT}/envs/${CONDA_ENV_TF}/bin/libfabric" ]; then
  ln -sf ${CONDA_ROOT}/envs/${CONDA_ENV_TF}/bin/libfabric/fi_* ${CONDA_ROOT}/envs/${CONDA_ENV_TF}/bin/
fi

# Make sure the S2I source directory is empty as we will use the image
# produced to run further S2I builds.

(shopt -s dotglob ; rm -rf ${APP_ROOT}/src/*)
