{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Intel® oneAPI AI Analytics Toolkit on RedHat OpenShift Data Science!\n",
    "This document covers the basics of Intel® oneAPI AI Analytics Toolkit (AI Kit)on RedHat OpenShift Data Science for Data Science Projects. It provides information on where to access certain Intel AI optimizations within the AI Analytics Toolkit pre-built kernel environments, and more resources on examples and how to find more information on Intel® oneAPI AI Analytics Toolkit.\n",
    "\n",
    "## Overview of Intel® oneAPI AI Analytics Toolkit\n",
    "The Intel® oneAPI AI Analytics Toolkit gives data scientists, AI developers, and researchers familiar Python* tools and frameworks to accelerate end-to-end data science and machine learning pipelines on Intel® architectures. The components are built using oneAPI libraries for low-level compute optimizations. This toolkit maximizes performance from preprocessing through machine and deep learning phases and provides interoperability for efficient model development and deployment across single and multinodes. \n",
    "\n",
    "Using this toolkit, you can:\n",
    "\n",
    "- Deliver high-performance deep learning (DL) training and inference on Intel® XPUs with Intel-optimized DL frameworks: TensorFlow* and PyTorch*, pretrained models, and Intel Low Precision Optimization Tool.  \n",
    "\n",
    "- Achieve drop-in acceleration for data preprocessing and machine learning workflows with compute-intensive Python packages: Modin*, Scikit-Learn*, and XGBoost* optimized for Intel..\n",
    "\n",
    "- Seamlessly scale up and scale out to leverage AI compute continuum across single and multi nodes\n",
    "\n",
    "- Gain direct access to Intel’s latest machine and deep learning optimizations in a single integrated package tested for interoperability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Intel® oneAPI AI Analytics Toolkit Pre-built Environment Packages Information](#sec-env)\n",
    "2. [Intel® oneAPI AI Analytics Toolkit Getting Started Resources](#sec-gettingstarted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-env\"></a>\n",
    "## 1. Intel® oneAPI AI Analytics Toolkit Environment Packages Information\n",
    "\n",
    "You can find more detailed information on using the Intel® oneAPI AI Analytics Toolkit at <a href=\"software.intel.com/oneapi/ai-kit\">software.intel.com/oneapi/ai-kit</a>. \n",
    "\n",
    "On RedHat OpenShift Data Science, we have provided some pre-installed AI Kit environments based on different workload needs:\n",
    "\n",
    "**`Intel SKLearn, XGBoost, & Modin` Kernel Environment**\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/distribution-of-modin.html\">Intel® Distribution of Modin*</a>\n",
    "- <a href=\"https://intel.github.io/scikit-learn-intelex/\">Intel® Extension for Scikit-Learn*</a>\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/distribution-for-python.html\">Intel® Distribution for Python (including Intel optimizations for NumPy and SciPy)</a>\n",
    "- <a href=\"https://xgboost.readthedocs.io/en/latest/python/index.html\">Intel Optimized XGBoost</a>\n",
    "\n",
    "**`Intel PyTorch & Quantization` Kernel Environment**\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/frameworks.html#tensor-flow\">Intel® Optimization for TensorFlow</a>\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/lpot.html\">Intel® Low Precision Optimization Tool</a>\n",
    "- <a href=\"https://github.com/IntelAI/models\">Model Zoo for Intel® Architecture</a>\n",
    "\n",
    "**`Intel TensorFlow & Quantization` Kernel Environment**\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/frameworks.html#pytorch\">Intel® Optimization for PyTorch</a>\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/lpot.html\">Intel® Low Precision Optimization Tool</a>\n",
    "- <a href=\"https://github.com/IntelAI/models\">Model Zoo for Intel® Architecture</a>\n",
    "\n",
    "You can also create and install additional AI kit packages and environments on RedHat OpenShift Data Science using <a href=\"https://software.intel.com/content/www/us/en/develop/articles/installing-ai-kit-with-conda.html\">Conda* Package Manager</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sec-gettingstarted\"></a>\n",
    "## 2. Intel® oneAPI AI Analytics Toolkit Getting Started Resources\n",
    "As part of the Intel® oneAPI AI Analytics Toolkit on RedHat OpenShift Data Science, we have provided you three examples to help you get started with different AI Kit optimizations. These can be found in the `oneAPI-samples.git` directory.\n",
    "\n",
    "For even more examples and information on AI Kit optimizations consider visiting the following resources:\n",
    "- <a href=\"https://software.intel.com/oneapi/ai-kit\">Intel® oneAPI AI Analytics Toolkit Website</a>\n",
    "- <a href=\"https://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics\">Intel® oneAPI AI Analytics Toolkit Code Samples</a>\n",
    "- <a href=\"https://software.intel.com/content/www/us/en/develop/articles/oneapi-ai-analytics-toolkit-release-notes.html\">Intel® oneAPI AI Analytics Toolkit Release Notes</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
